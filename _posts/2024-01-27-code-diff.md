---
layout: post
title: 6-DOF Grasping series - how to handle collisions
date: 2024-02-19
description: this is how you can display code diffs
tags: formatting code
categories: sample-posts
code_diff: true
toc:
  beginning: true
---

## overall thoughts

grasp synthesis in clutter: grasp (target) + collision avoidance

## Adding a Table of Contents

some terminologies:
- rejection sampling
- negative sampling
- hard negative sampling

Two inspiring papers from professor Dieter Fox. A generative model (learn from positive graps) + collision checking model for evaluation/improvement. (also in today's llm for robotics? generation + evaluation podcast 02/05 TWIML)

our imitation learning also only learns only from positive samples. How far can only using positive samples go??


also sora generative model, Yann LeCun's twitter "Let me clear a *huge* misunderstanding here.
The generation of mostly realistic-looking videos from prompts *does not* indicate that a system understands the physical world.
Generation is very different from causal prediction from a world model.
The space of plausible videos is very large, and a video generation system merely needs to produce *one* sample to succeed.
The space of plausible continuations of a real video is *much* smaller, and generating a representative chunk of those is a much harder task, particularly when conditioned on an action.
Furthermore, generating those continuations would be not only expensive but totally pointless.
It's much more desirable to generate *abstract representations* of those continuations that eliminate details in the scene that are irrelevant to any action we might want to take."
1. 
2. [6-DOF Grasping for Target-driven Object Manipulation in Clutter](https://arxiv.org/pdf/1912.03628.pdf) distinguish between grasp failures due to collisions and target geometry

### 6-DOF GraspNet: Variational Grasp Generation for Object Manipulation
#### model

### 6-DOF Grasping for Target-driven Object Manipulation in Clutter
#### model
- input: depth image of the scene + binary mask indicating the target object
- target: 
$$ P(G^*|X) $$, 
where $$ X $$ is the point cloud observation and $$ G^* $$ is the space of successful grasps.
- problem breakdown: a generator 
$$ P(G^*|X_o) $$ (ignoring clutter)
and a discriminator $$ P(C|X, g) $$ (CollisionNet), captures collisions $$ C $$ between gripper at pose $$ g $$ and clutter observed as $$ X $$. $$ X_o $$ is the point cloud of the target object.
- problem: only have positive samples --> solution: grasp refinement


